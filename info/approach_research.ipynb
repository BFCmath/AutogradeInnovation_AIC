{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Current public solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "The current solutions in this field tend to integrate various computer vision and image processing techniques as follows:\n",
    "\n",
    "1.  **Classical Computer Vision with Geometric Transformation and Morphology Operations**\n",
    "    *   **Techniques:** Hough Transforms for detecting lines and circles, corner detection (e.g., Harris corner detection), and perspective transformation or homography to correct for skew and perspective distortions.\n",
    "    *   **Morphology Operations** dilation and erosion help in cleaning up the binarized image\n",
    "    *   **ROI Extraction:** Predefined coordinates are used to extract areas containing the bubbles and student information, or algorithms like contour detection can be used to dynamically extract the answer areas.\n",
    "    *   **Answer Detection:** Pixel analysis to find which regions are most filled for multiple-choice bubbles (e.g., measuring the sum of pixel values inside each bubble). For written answers, template matching could be applied.\n",
    "\n",
    "    *   **Pros:** Well-established algorithms that are fast and easy to implement.\n",
    "    *   **Cons:** May struggle with varying lighting conditions, uneven filling of bubbles, and complex handwriting. May require manual calibration and tuning for each new form.\n",
    "    *   **Examples:** OpenCV with standard functions.\n",
    "\n",
    "2.  **Image Segmentation with Machine Learning**\n",
    "    *   **Techniques:** Train convolutional neural networks (CNNs), like U-Net or Mask-RCNN to find each bubble and separate the student ID area from the answer area.\n",
    "    *   **ROI Extraction:** With a pre-trained neural network, we could extract the bubble answers, or the student ID areas.\n",
    "    *   **Answer Detection:** Once the bubble is extracted, it is possible to detect which bubble was selected, or a CNN can directly classify the answer given in the image.\n",
    "    *   **Pros:** Very good at detecting and classifying objects (student ID, bubbles, and answers) with high accuracy, robust to noise and variation.\n",
    "    *   **Cons:** Requires a substantial amount of labeled data to train well, computational expensive.\n",
    "    *   **Examples:** TensorFlow, PyTorch.\n",
    "\n",
    "3. **Optical Character Recognition (OCR)**\n",
    "    *   **Techniques**: Once the answer area (e.g., student ID, written answers) is extracted, an OCR engine like Tesseract is used to identify and extract text data\n",
    "    *   **Pros**: Great for extracting text data and digit.\n",
    "    *   **Cons**: Could be affected by low quality, and handwriting.\n",
    "    *   **Examples**: Tesseract, EasyOCR\n",
    "\n",
    "4.  **Deep Learning for Answer Classification**\n",
    "    *   **Techniques:** Using CNNs directly for answer detection and classification. It can learn a high-level feature representation and directly detect the answer from images, without explicitly segmentation\n",
    "    *   **Answer Detection:** A convolutional network is trained to classify the answer from extracted region\n",
    "    *   **Pros:** Highly accurate and robust; learns directly from data and reduces manual steps\n",
    "    *   **Cons:** Requires large labeled datasets and significant computation resources\n",
    "    *   **Examples:** TensorFlow, PyTorch, Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Citations and Key Research Papers\n",
    "\n",
    "Here are some references to relevant research in this area, although specific citations may be more focused on particular sub-problems:\n",
    "\n",
    "*   **Multiple-Choice Answer Sheet Processing**\n",
    "    *   **Paper**: \"Automatic Multiple-Choice Test Grading System Based on Image Processing and Machine Learning\" - This could be a generic title that you will find in IEEE, ACM and other engineering conferences\n",
    "    *   **Key Idea**: Introduces the general workflow using computer vision techniques.\n",
    "*   **Optical Mark Recognition (OMR) Techniques:**\n",
    "    *   **Paper**: \"Automatic Evaluation of Multiple-Choice Questionnaires with Deep Convolutional Networks\" - search in ACM, Elsevier\n",
    "    *   **Key Idea:** Using Deep Learning for automatically detect and classifying the answers in bubble areas\n",
    "*  **Form Processing**\n",
    "    *   **Paper**: \"Automatic Form Processing System using Deep Learning\".\n",
    "    *   **Key Idea**: Proposes a workflow with deep learning and OCR for form processing\n",
    "\n",
    "**Note:** The exact titles of papers might vary; you'd need to search in academic databases like IEEE Xplore, ACM Digital Library, or Google Scholar using keywords like \"automated grading,\" \"optical mark recognition,\" \"OMR,\" \"form processing,\" \"deep learning,\" \"answer sheet,\" etc.\n",
    "\n",
    "## Applying to Your Specific Case\n",
    "\n",
    "Looking at the image you provided, here's how an approach could be broken down:\n",
    "\n",
    "1.  **Preprocessing:** Noise reduction, skew correction, and perspective transformation are essential due to the scan quality.\n",
    "2.  **ROI Extraction:**\n",
    "    *   Detect the bounding boxes around the bubbles (multiple-choice sections) using geometric transformation and contour detection.\n",
    "    *   Detect the area where the written information is stored, and where the student ID areas are located using pre-defined coordinate or contour detection.\n",
    "3. **Answer Detection**\n",
    "    * For multiple-choice, perform pixel analysis inside each bubble to determine which one is selected\n",
    "    * For numerical answers, use an OCR library like Tesseract.\n",
    "    * For checkbox-style answers, analyze pixel intensities in the checkbox regions.\n",
    "4.  **Grading:**\n",
    "    *   Compare detected answers with the answer key, counting number of correct answers for the multiple-choice section and correct numerical value for the fill-in-the-blank section.\n",
    "\n",
    "## Summary\n",
    "\n",
    "Automated grading systems for student answer sheets present a compelling area where computer vision techniques help ease grading workflows. The best approach depends on the specific needs, data quality, accuracy requirements and available resources. The current landscape offers robust solutions by blending classical vision with machine learning techniques, ensuring accuracy and reliability.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
